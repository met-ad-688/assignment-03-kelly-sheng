---
title: Assignment 03
author:
  - name: Kelly Sheng
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2025-09-24'
format:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2
date-modified: today
date-format: long
execute:
  echo: true
  eval: true
  freeze: auto
---

# Setup
```{python}
import pandas as pd
import plotly.express as px
import plotly.io as pio
from pyspark.sql import SparkSession
import re
import numpy as np
import plotly.graph_objects as go
from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when
from pyspark.sql import functions as F
from pyspark.sql.functions import col, monotonically_increasing_id

pio.templates["nike"] = go.layout.Template(
   layout = {
       'title':
           {'font': {'family': 'HelveticaNeue-CondensedBold, Helvetica, Sans-serif',
                     'size':30,
                     'color': '#333'}
           },
       'font': {'family': 'Helvetica Neue, Helvetica, Sans-serif',
                     'size':16,
                     'color': '#333'},
       'colorway': ['#e622a9', '#49bcca'],
       'hovermode': 'x unified'
   },
   data = {
       'bar': [go.Bar(texttemplate = '%{value:$.2s}',
                      textposition='outside',
                      textfont={'family': 'Helvetica Neue, Helvetica, Sans-serif',
                                'size': 20,
                                'color': '#FFFFFF'
                                })]
   }
)
px.defaults.template = "nike"
pio.templates.default = "nike"
```

```{python}
# | eval: true
np.random.seed(42)

pio.renderers.default = "notebook"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("data/lightcast_job_postings.csv")
df.createOrReplaceTempView("job_postings")
```

## Casting Salary and Experience Columns
```{python}
# | eval: true
df = df.withColumn("SALARY", col("SALARY").cast("float")) \
    .withColumn("SALARY_FROM", col("SALARY_FROM").cast("float")) \
    .withColumn("SALARY_TO", col("SALARY_TO").cast("float")) \
    .withColumn("MIN_YEARS_EXPERIENCE", col("MIN_YEARS_EXPERIENCE").cast("float")) \
    .withColumn("MAX_YEARS_EXPERIENCE", col("MAX_YEARS_EXPERIENCE").cast("float"))
```

## Computing Medians
```{python}
# | eval: true
median_from = df.approxQuantile("SALARY_FROM", [0.5], 0.01)[0]
median_to = df.approxQuantile("SALARY_TO", [0.5], 0.01)[0]
median_salary = df.approxQuantile("SALARY", [0.5], 0.01)[0]
print("median_from: ", f"${median_from:,.2f}")
print("median_to: ", f"${median_to:,.2f}")
print("median_salary: ", f"${median_salary:,.2f}")
```

## Imputing Missing Salaries
``` {python}
# | eval: true
df = df.fillna({
    "SALARY_FROM": median_from,
    "SALARY_TO": median_to,
    "SALARY": median_salary
})

df = df.withColumn("Average_Salary", (col("SALARY_FROM") + col("SALARY_TO")) / 2)
```

## Cleaning Education Columns
``` {python}
# | eval: true
df = df.withColumn(
    "EDUCATION_LEVELS_NAME",
    regexp_replace(col("EDUCATION_LEVELS_NAME"), r"[\n\r]", "")
)
```

## Exporting Cleaned Data
``` {python}
# | eval: true
export_cols = [
  "EDUCATION_LEVELS_NAME",
  "REMOTE_TYPE_NAME",
  "MAX_YEARS_EXPERIENCE",
  "Average_Salary",
  "SALARY",
  "LOT_V6_SPECIALIZED_OCCUPATION_NAME",
  "EMPLOYMENT_TYPE_NAME",
  "NAICS2_NAME",
  "ONET_NAME"
]
df_selected = df.select(*export_cols)
pdf = df_selected.toPandas()
pdf.to_csv("data/lightcast_cleaned.csv", index=False)

print("Data cleaning complete. Rows retained: ", len(pdf))
```

# Salary Distribution by Industry and Employment Type
```{python}
pdf_industry = (
    df_selected
    .filter((df_selected["SALARY"] > 0) & (df_selected["EMPLOYMENT_TYPE_NAME"].isNotNull()))
    .select("EMPLOYMENT_TYPE_NAME", "SALARY", "NAICS2_NAME")
    .toPandas()
)

pdf_industry["EMPLOYMENT_TYPE_NAME"] = pdf_industry["EMPLOYMENT_TYPE_NAME"].apply(
    lambda x: re.sub(r"[^\x00-\x7F]", "", x)
)

median_salaries = pdf_industry.groupby("EMPLOYMENT_TYPE_NAME")["SALARY"].median()

sorted_employment_types = median_salaries.sort_values(ascending=False).index

pdf_industry["EMPLOYMENT_TYPE_NAME"] = pd.Categorical(
    pdf_industry["EMPLOYMENT_TYPE_NAME"],
    categories=sorted_employment_types,
    ordered=True
)

fig = px.box(
    pdf_industry,
    x="NAICS2_NAME",
    y="SALARY",
    title="Salary Distribution by Industry",
    color="EMPLOYMENT_TYPE_NAME",
    boxmode="group",
    points="all",
    labels={"NAICS2_NAME": "Industry", "SALARY": "Salary", "EMPLOYMENT_TYPE_NAME": "Employment Type"},
    height=800
)

fig.write_html("figures/Q1.html")
fig.write_image("figures/Q1.svg")
```
## Analysis
The box plot shows that most industries have high variance in their job listings, with outliers making up the majority of industries like Retail Trade, Finance and Insurance, and Construction. However, industries like Public Administration and Educational Services are more naturally distributed, which makes sense given they are often government roles with fixed salaries. This plot shows that full-time salaries tend to be higher by median, but more volatile as well.

![](./figures/Q1.svg)

# Salary Analysis by ONET Occupation Type (Bubble Chart)
```{python}
salary_analysis = spark.sql("""
  SELECT
        LOT_V6_OCCUPATION_NAME AS ONET_NAME,
        PERCENTILE(SALARY, 0.5) AS Median_Salary,
        COUNT(*) AS Job_Postings
  FROM job_postings
  GROUP BY LOT_V6_OCCUPATION_NAME
  ORDER BY Job_Postings DESC
  LIMIT 10
""")

salary_pd = salary_analysis.toPandas()

fig = px.scatter(
    salary_pd,
    x="ONET_NAME",
    y="Median_Salary",
    size="Job_Postings",
    color="Median_Salary",
    color_continuous_scale="armyrose",
    labels={"ONET_NAME": "ONET Occupation", "Median_Salary": "Median Salary", "Job_Postings": "Number of Job Postings"},
    hover_name="ONET_NAME",
    size_max=60,
    height=800
)

fig.write_html("figures/Q2.html")
fig.write_image("figures/Q2.svg")
```
## Analysis
There is much higher demand for Data and Data Mining Analysts, but their median salary is over 60K lower than Compyter Systems Engineers and Architects. Meanwhile, Clinical Analysts and Market Research Analysts are both low in demand and do not make more than other analysts on this list.
![](./figures/Q2.svg)

# Salary by Education Level
```{python}
pdf_edu = df_selected.toPandas()

conditions = [
    pdf_edu["EDUCATION_LEVELS_NAME"].str.contains("GED|Associate|No Education", case=False, na=True),
    pdf_edu["EDUCATION_LEVELS_NAME"].str.contains("Bachelor", case=False, na=True),
    pdf_edu["EDUCATION_LEVELS_NAME"].str.contains("Master", case=False, na=True),
    pdf_edu["EDUCATION_LEVELS_NAME"].str.contains("PhD|Doctorate|Professional", case=False, na=True)
]

choices = [
    "Associate or Lower",
    "Bachelor's",
    "Master's",
    "PhD"
]

pdf_edu["Education_Group"] = np.select(conditions, choices, default="Other")

pdf_edu = pdf_edu[pdf_edu["Education_Group"].isin(["Associate or Lower", "Bachelor's", "Master's", "PhD"])]

edu_groups = ["Associate or Lower", "Bachelor's", "Master's", "PhD"]

pdf_edu["Experience_Jitter"] = pdf_edu["MAX_YEARS_EXPERIENCE"] + np.random.uniform(-0.1, 0.1, size=len(pdf_edu))

fig = px.scatter(
    pdf_edu,
    x="Experience_Jitter",
    y="Average_Salary",
    color="Education_Group",
    color_continuous_scale="delta",
    title="Salary vs Experience by Education Level",
    labels={
        "Experience_Jitter": "Max Years of Experience",
        "Average_Salary": "Average Salary",
        "Education_Group": "Education Level"
    },
    height=600,
    width=1200
)

fig.write_html("figures/Q3.html")
fig.write_image("figures/Q3.svg")
```
## Analysis
This plot shows that average salary is slightly more correlated to years of experience compared to education level. There is a clear uptrend along the x-axis for years of experience, but the various degrees are comingled with just a few outliers, which suggests that, rather than the overarching degree, analyzing salary by education level requires additional nuance such as the specific degree studied. For example, a PhD in food science may earn less than a bachelor's in computer science, but this graph does not make that key distinction.
![](./figures/Q3.svg)

# Salary by Remote Work Type
```{python}
pdf_remote = df_selected.select(
    "REMOTE_TYPE_NAME", "MAX_YEARS_EXPERIENCE", "SALARY", "LOT_V6_SPECIALIZED_OCCUPATION_NAME"
).toPandas()

pdf_remote["Remote_Group"] = pdf_remote["REMOTE_TYPE_NAME"].str.lower()
pdf_remote["Remote_Group"] = pdf_remote["Remote_Group"].fillna("Onsite")
pdf_remote["Remote_Group"] = pdf_remote["Remote_Group"].replace({
    "": "Onsite",
    "Not Remote": "Onsite",
    "Hybrid Remote": "Hybrid"
})

pdf_remote = pdf_remote.rename(columns={"SALARY": "Average_Salary"})

pdf_remote["Experience_Jitter"] = pdf_remote["MAX_YEARS_EXPERIENCE"] + np.random.uniform(-0.2, 0.2, size=len(pdf_remote))

fig = px.scatter(
    pdf_remote,
    x="Experience_Jitter",
    y="Average_Salary",
    color="Remote_Group",
    hover_data=["LOT_V6_SPECIALIZED_OCCUPATION_NAME"],
    title="Salary vs Experience by Remote Work Type (Scatter with Jitter)",
    labels={
        "Experience_Jitter": "Max Years of Experience",
        "Average_Salary": "Average Salary",
        "Remote_Group": "Remote Type"
    },
    height=600
)

fig.write_html("figures/Q4a.html")
fig.write_image("figures/Q4a.svg")
```

```{python}
fig = px.histogram(
    pdf_remote,
    x="Average_Salary",
    color="Remote_Group",
    barmode="overlay",
    nbins=50,
    title="Salary Distribution by Remote Work Type",
    labels={"Average_Salary": "Average Salary", "Remote_Group": "Remote Type"},
    height=500,
    opacity=0.7
)
fig.write_html("figures/Q4b.html")
fig.write_image("figures/Q4b.svg")
```
## Analysis
There doesn't seem to be a strong correlation between salary and remote work type; the variance for onsite is generally higher, whereas hybrid is lower. The difference in data between remote work types is not drastic enough to indicate a real trend.

